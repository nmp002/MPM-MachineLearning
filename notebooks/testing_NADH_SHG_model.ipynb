{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "from models.microscopy_cnn import MicroscopyCNN\n",
    "import torch\n",
    "from scripts.dataset_loader import MicroscopyDataset\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = MicroscopyCNN(in_channels=2, task='classification')\n",
    "\n",
    "# model.load_state_dict(torch.load(r'C:\\Users\\nmp002\\PycharmProjects\\MPM-MachineLearning\\trained_models\\best_NADH_only_24FEB2025.pt', map_location=torch.device('cpu'),weights_only=True))\n",
    "model.load_state_dict(torch.load(r'C:\\Users\\nmp002\\PycharmProjects\\MPM-MachineLearning\\trained_models\\epoch250_NADH_SHG.pt', map_location=torch.device('cpu'),weights_only=True))"
   ],
   "id": "a55b39c11dd1f2a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "csv_file=r\"C:\\Users\\nmp002\\PycharmProjects\\MPM-MachineLearning\\data\\newData\\labels.csv\"\n",
    "root_dir=r\"C:\\Users\\nmp002\\PycharmProjects\\MPM-MachineLearning\\data\\newData\"\n",
    "\n",
    "dataset = MicroscopyDataset(\n",
    "    csv_file=csv_file,\n",
    "    root_dir=root_dir,\n",
    "    # channels = ['nadh'],\n",
    "    channels = ['nadh', 'shg'],\n",
    "    transform=None\n",
    ")"
   ],
   "id": "f8c48aaf07ca03cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "specific_test_paths = []\n",
    "# sample_indices = [23,0,3,20]\n",
    "sample_indices = range(0,29)\n",
    "eval_indices = [27, 4, 25, 7, 8]\n",
    "for sample_index in eval_indices:\n",
    "    if sample_index not in [25,7]:\n",
    "        specific_test_paths.append(dataset.sample_wise_paths[sample_index])\n",
    "\n",
    "print(specific_test_paths)\n",
    "# print('\\n------------------------------------------\\n')\n",
    "# print(dataset.sample_wise_paths)"
   ],
   "id": "1b77e2c009e35a02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def score_em(t, o):\n",
    "    fpr, tpr, thresholds = roc_curve(t, o)\n",
    "    score = auc(fpr, tpr)\n",
    "    score_all = roc_auc_score(t, o)\n",
    "    print(score_all)\n",
    "    thresh = thresholds[np.argmax(tpr - fpr)]\n",
    "    print(type(thresholds), type(thresh))\n",
    "    preds = [out >= thresh for out in o]\n",
    "    for tar,pred in zip(t, preds):\n",
    "        print(f'{tar} -> {pred}')\n",
    "    RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=score).plot()\n",
    "    ConfusionMatrixDisplay.from_predictions(t, preds).plot()"
   ],
   "id": "a5c055496e6129c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import auc, roc_curve, confusion_matrix, RocCurveDisplay, ConfusionMatrixDisplay\n",
    "from scripts.dataset_loader import tiff_to_tensor\n",
    "import numpy as np\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    targets = []\n",
    "    all_targets = []\n",
    "    outs = []\n",
    "    all_outs = []\n",
    "    for sample in specific_test_paths:\n",
    "        fov_outs = []\n",
    "        if sample:\n",
    "            for fov in sample:\n",
    "                # De-nest fov paths and get the indexed item path\n",
    "                score = fov[1]\n",
    "                combined_image = torch.cat([tiff_to_tensor(channel) for channel in fov[0]], dim=0).unsqueeze(0)\n",
    "                y = model(combined_image).item()\n",
    "                all_outs.append(y)\n",
    "                fov_outs.append(y)\n",
    "                all_targets.append(1 if score > 25 else 0)\n",
    "            targets.append(1 if score > 25 else 0)\n",
    "            outs.append(np.mean(fov_outs))\n",
    "score_em(all_targets, all_outs)\n",
    "score_em(targets, outs)"
   ],
   "id": "d568c1f7ec85984",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(all_outs)",
   "id": "d17810cccd93c374",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# best NADH_SHG = 0.5153061224489796\n",
    "# epoch500 NADH_SHG ="
   ],
   "id": "5291fbd3df7bd03e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(fov_outs)",
   "id": "6024565ca1635453",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(targets)",
   "id": "2fd545cd3a129ef1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(outs)",
   "id": "76cef5467801b5a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_channels = ['nadh','shg']\n",
    "# Load full dataset\n",
    "full_dataset = MicroscopyDataset(\n",
    "    csv_file=\"../data/newData/labels.csv\",\n",
    "    root_dir=\"../data/newData\",\n",
    "    channels = input_channels,\n",
    "    transform=None\n",
    ")"
   ],
   "id": "db237d663fc83ec8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(full_dataset.sample_wise_paths)",
   "id": "8e70e2bce0fdb45f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "samples_list = full_dataset.sample_wise_paths\n",
    "print(samples_list)"
   ],
   "id": "750c1d3d99755667",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "random.shuffle(samples_list)\n",
    "print(samples_list)"
   ],
   "id": "4afc96a9cd5b7abf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torchvision.transforms.v2 as tvt\n",
    "# Transformations for training set\n",
    "train_transform = tvt.Compose([\n",
    "    tvt.RandomVerticalFlip(p=0.25),\n",
    "    tvt.RandomHorizontalFlip(p=0.25),\n",
    "    tvt.RandomRotation(degrees=(-180, 180))])\n",
    "full_dataset.transform = train_transform"
   ],
   "id": "879c16df30debe74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T16:13:50.399117Z",
     "start_time": "2025-03-05T16:13:50.396005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_samples = len(samples_list)\n",
    "train_size = int(0.7 * total_samples)\n",
    "val_size = int(0.2 * total_samples)\n",
    "test_size = total_samples - train_size - val_size\n",
    "\n",
    "indices = torch.utils.data.SubsetRandomSampler(range(len(samples_list)))"
   ],
   "id": "1f6c7691535fd89c",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "indices = [i for i in indices]\n",
    "for i in indices:\n",
    "    print(f'Sample {i} is class -> {samples_list[i][0][1] > 25}')"
   ],
   "id": "8aae929eb0655f00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T16:12:46.640837Z",
     "start_time": "2025-03-05T16:12:46.632844Z"
    }
   },
   "cell_type": "code",
   "source": "print(indices)",
   "id": "c664618d7c34db8b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 7, 21, 16, 17, 11, 28, 1, 22, 4, 27, 23, 2, 3, 9, 10, 26, 18, 5, 25, 20, 19, 0, 24, 13, 6, 12, 15, 14]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample_id = full_dataset.data_frame['sample_id'].iloc[9]\n",
    "for i, fov_path in enumerate(full_dataset._denest()):\n",
    "        print(fov_path[0][0])"
   ],
   "id": "57f3ec3464fca58b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(indices)\n",
    "train_samples = indices[:train_size]\n",
    "print(f\"Train samples: {train_samples}\")\n",
    "train_indices = [full_dataset.get_sample_indices(sample) for sample in train_samples]\n",
    "train_indices = [i for sublist in train_indices for i in sublist]\n",
    "print(f\"Train indices: {train_indices}\")\n",
    "train_data = torch.utils.data.Subset(full_dataset.sample_wise_paths, train_indices)\n",
    "\n",
    "\n",
    "val_samples = indices[train_size:train_size+val_size]\n",
    "print(f\"Val samples: {val_samples}\")\n",
    "val_indices = [full_dataset.get_sample_indices(sample) for sample in val_samples]\n",
    "val_indices = [i for sublist in val_indices for i in sublist]\n",
    "print(f\"Val indices: {val_indices}\")\n",
    "val_data = torch.utils.data.Subset(full_dataset.sample_wise_paths, val_indices)\n",
    "\n",
    "test_samples = indices[train_size+val_size:]\n",
    "print(f\"Test samples: {test_samples}\")\n",
    "test_indices = [full_dataset.get_sample_indices(sample) for sample in test_samples]\n",
    "test_indices = [i for sublist in test_indices for i in sublist]\n",
    "print(f\"Test indices: {test_indices}\")\n",
    "test_data = torch.utils.data.Subset(full_dataset.sample_wise_paths, test_indices)"
   ],
   "id": "84d2d0aa054bff7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataloaders = {\n",
    "    'train': DataLoader(train_data, batch_size=16, shuffle=True),\n",
    "    'val': DataLoader(val_data, batch_size=16, shuffle=False),\n",
    "    'test': DataLoader(test_data, batch_size=16, shuffle=False)\n",
    "}"
   ],
   "id": "8bcf83d54636bf76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for id_num in train_samples:\n",
    "    print(f\"Sample_{(id_num+1):03}\")"
   ],
   "id": "2f2ed74aa1f66bd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_samples = len(samples_list)\n",
    "train_size = int(0.7 * total_samples)\n",
    "val_size = int(0.2 * total_samples)\n",
    "test_size = total_samples - train_size - val_size\n",
    "print(f\"Total samples: {total_samples}, train_size: {train_size}, val_size: {val_size}, test_size: {test_size}\")"
   ],
   "id": "64a051a4d22e2a7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_samples = samples_list[:train_size]\n",
    "val_samples = samples_list[train_size:train_size+val_size]\n",
    "test_samples = samples_list[train_size+val_size:]\n",
    "print(f\"Train samples: {train_samples}\\n\\nval samples: {val_samples}\\n\\ntest samples: {test_samples}\")"
   ],
   "id": "8e52bf14ab23917e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for sample in test_data:\n",
    "    for fov in sample:\n",
    "        score = fov[1]\n",
    "        print(score)"
   ],
   "id": "43727d3d3fb0dd40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3f651122479ece4f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
