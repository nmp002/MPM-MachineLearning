{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from torch.ao.nn.quantized.functional import threshold\n",
    "\n",
    "from models.microscopy_cnn import MicroscopyCNN\n",
    "from scripts.model_metrics import score_model\n",
    "import torch\n",
    "from scripts.dataset_loader import MicroscopyDataset\n",
    "from torch.utils.data import DataLoader"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = MicroscopyCNN(in_channels=2, task='classification')\n",
    "\n",
    "# model.load_state_dict(torch.load(r'C:\\Users\\nmp002\\PycharmProjects\\MPM-MachineLearning\\trained_models\\best_NADH_only_24FEB2025.pt', map_location=torch.device('cpu'),weights_only=True))\n",
    "model.load_state_dict(torch.load(r'C:\\Users\\nmp002\\PycharmProjects\\MPM-MachineLearning\\trained_models\\epoch250_NADH_SHG.pt', map_location=torch.device('cpu'),weights_only=True))"
   ],
   "id": "a55b39c11dd1f2a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "csv_file=r\"C:\\Users\\nmp002\\PycharmProjects\\MPM-MachineLearning\\data\\newData\\labels.csv\"\n",
    "root_dir=r\"C:\\Users\\nmp002\\PycharmProjects\\MPM-MachineLearning\\data\\newData\"\n",
    "\n",
    "dataset = MicroscopyDataset(\n",
    "    csv_file=csv_file,\n",
    "    root_dir=root_dir,\n",
    "    # channels = ['nadh'],\n",
    "    channels = ['nadh', 'shg'],\n",
    "    transform=None\n",
    ")"
   ],
   "id": "f8c48aaf07ca03cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "specific_test_paths = []\n",
    "# sample_indices = [23,0,3,20]\n",
    "sample_indices = range(0,29)\n",
    "eval_indices = [27, 4, 25, 7, 8]\n",
    "for sample_index in eval_indices:\n",
    "    if sample_index not in [25,7]:\n",
    "        specific_test_paths.append(dataset.sample_wise_paths[sample_index])\n",
    "\n",
    "print(specific_test_paths)\n",
    "# print('\\n------------------------------------------\\n')\n",
    "# print(dataset.sample_wise_paths)"
   ],
   "id": "1b77e2c009e35a02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def score_em(t, o):\n",
    "    fpr, tpr, thresholds = roc_curve(t, o)\n",
    "    score = auc(fpr, tpr)\n",
    "    score_all = roc_auc_score(t, o)\n",
    "    print(score_all)\n",
    "    thresh = thresholds[np.argmax(tpr - fpr)]\n",
    "    print(type(thresholds), type(thresh))\n",
    "    preds = [out >= thresh for out in o]\n",
    "    for tar,pred in zip(t, preds):\n",
    "        print(f'{tar} -> {pred}')\n",
    "    RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=score).plot()\n",
    "    ConfusionMatrixDisplay.from_predictions(t, preds).plot()"
   ],
   "id": "a5c055496e6129c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import auc, roc_curve, confusion_matrix, RocCurveDisplay, ConfusionMatrixDisplay\n",
    "from scripts.dataset_loader import tiff_to_tensor\n",
    "import numpy as np\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    targets = []\n",
    "    all_targets = []\n",
    "    outs = []\n",
    "    all_outs = []\n",
    "    for sample in specific_test_paths:\n",
    "        fov_outs = []\n",
    "        if sample:\n",
    "            for fov in sample:\n",
    "                # De-nest fov paths and get the indexed item path\n",
    "                score = fov[1]\n",
    "                combined_image = torch.cat([tiff_to_tensor(channel) for channel in fov[0]], dim=0).unsqueeze(0)\n",
    "                y = model(combined_image).item()\n",
    "                all_outs.append(y)\n",
    "                fov_outs.append(y)\n",
    "                all_targets.append(1 if score > 25 else 0)\n",
    "            targets.append(1 if score > 25 else 0)\n",
    "            outs.append(np.mean(fov_outs))\n",
    "score_em(all_targets, all_outs)\n",
    "score_em(targets, outs)"
   ],
   "id": "d568c1f7ec85984",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(all_outs)",
   "id": "d17810cccd93c374",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# best NADH_SHG = 0.5153061224489796\n",
    "# epoch500 NADH_SHG ="
   ],
   "id": "5291fbd3df7bd03e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(fov_outs)",
   "id": "6024565ca1635453",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(targets)",
   "id": "2fd545cd3a129ef1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(outs)",
   "id": "76cef5467801b5a5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
